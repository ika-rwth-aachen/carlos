<img src="../utils/images/data-driven-development-icon.png" height=100 align="right">

# Use Case: *Data-Driven Development*

>[!NOTE]
> **Background**: The *data-driven development* use case covers development processes using large amounts of data, which are not effectively obtainable in real-world settings, thus motivating simulations. For many applications, simulative data can be sufficiently accurate to be integrated into the data-driven development process. This includes training data for machine learning algorithms but also closed-loop reinforcement learning. Potentially interesting data includes raw sensor but also dynamic vehicle data in a wide variety at large scale. Simulations additionally enable data generation beyond the physical limits of vehicle dynamics or sensor configurations. To accumulate large amounts of data, relevant simulation parameters can be automatically sampled along different dimensions. Subsequently, automation and parallelization empower a cost-effective execution of multiple simulations, especially when using already established orchestration tools.

The subsequent demonstration showcases rapid *data driven development* and specifically addresses the following requirements:
- high simulation **fidelity**
- **flexibility** and containerization
- automation and **scalability**

## Getting Started

### Prerequisites

> [!IMPORTANT]  
> Make sure that all [system requirements](../utils/requirements.md) are fulfilled.
> Additionally, a Python installation is required on the host for this use case. We recommend using [conda](https://docs.conda.io/projects/conda/en/stable/index.html).

Install and activate the conda environment:

```bash
conda env install -f env/environment.yml
conda activate carlos_data_driven_development
```

Alternatively, you can also use pip:

```bash
pip install -r requirements.txt
```

### Data Generation

In the initial demo [software-prototyping](../software-prototyping), we demonstrated the integration of a Function Under Test (FUT) with CARLOS, exploring its capabilities through practical experimentation. While these tests validated the general functionality of our image segmentation module,  it became clear that there is considerable potential to improve its performance. Given that this module, like many AD functions, relies heavily on machine learning models trained with specific datasets, the quality and quantity of this training data are crucial.

#### Permutation-based Data Generation

Given that the specific nature of the data is less critical, the main objective is to generate as much and diverse data as possible. This can be effectively achieved through permutations of the simulation parameters, ensuring both quantity and diversity in the generated dataset.

Run the demo for permutation-based data generation:
```bash
python ./data_generation.py --config data-driven-delevopment-demo-image-segmentation.json
```

Data is generated by creating all possible permutations from a set of configuration parameters, managed through a JSON file-based data generation pipeline. Two examples are provided within this directory. While the current implementation is limited to the settings specified below, the [provided code](./src/) is modulare and can be easily customized to fit your requrements.

##### TODO Config table here

In addition to the already known components, we are introducing the `carla-client` here. This component enables the invocation of custom scripts through CARLA's PythonAPI, offering flexible configuration options for the simulation.

> [!NOTE]
> A detailed description of the individual components can be found in [components guide](../utils/components.md).

#### Scenario-based data generation

Assuming we improved our model, we are now aiming to evaluate its performance in targeted, real-world scenarios. Hence, we need to generate data in such scenarios, for which the scenario-based data generation feature can be utilized. In this example, we demonstrate how a list of OpenSCENARIO files can be integrated into the data generation pipeline as well.

```bash
python ./data_generation.py --config data-driven-delevopment-demo-scenario-execution.json
```

All scenarios are executed sequentially and data is generated. Following on that, in the third, [automatic testing demo](../automated-testing/README.md), concrete scenarios are used together with predefined metrics and automatically processed in a CI pipeline.